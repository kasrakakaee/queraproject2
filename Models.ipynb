{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score, classification_report\n",
    "#df to store metrics\n",
    "metrics_df_valid = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC-ROC'])\n",
    "metrics_df_test = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC-ROC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scale the data\n",
    "def scale(X, Y, Z):\n",
    "    scaler = StandardScaler()\n",
    "    X_ = scaler.fit_transform(X)\n",
    "    X__ = scaler.fit_transform(Y)\n",
    "    X___ = scaler.fit_transform(Z)\n",
    "    return X_, X__, X___\n",
    "\n",
    "#function to get the model parameters\n",
    "def info(X, Y, model_name, list_name):    \n",
    "    accuracy = accuracy_score(X, Y)\n",
    "    precision = precision_score(X, Y)\n",
    "    recall = recall_score(X, Y)\n",
    "    f1 = f1_score(X, Y)\n",
    "    auc = roc_auc_score(X, Y)\n",
    "    #print\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1)\n",
    "    print(\"AUC-ROC:\", auc)\n",
    "    print(classification_report(X, Y))\n",
    "\n",
    "    #adding results to the metrics_df\n",
    "    list_name.loc[len(list_name)] = [model_name, accuracy, precision, recall, f1, auc]\n",
    "    \n",
    "    #printing confusion matrix\n",
    "    confusion_mat = confusion_matrix(X, Y)\n",
    "    confusion_df = pd.DataFrame(confusion_mat, index=['Actual Negative', 'Actual Positive'],\n",
    "                             columns=['Predicted Negative', 'Predicted Positive'])\n",
    "    print(confusion_df)\n",
    "\n",
    "#function to train the model\n",
    "def train_model(X, Y, X_test, k=1):\n",
    "    svm = SVC(kernel='linear',C=k)\n",
    "    svm.fit(X, Y)\n",
    "    predicted = svm.predict(X_test)\n",
    "    return predicted\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "train = pd.read_csv('random_forest_train.csv')\n",
    "test = pd.read_csv('random_forest_test.csv')\n",
    "\n",
    "#converting date to datetime and then converting to integer\n",
    "train['Date'] = pd.to_datetime(train['Date'])\n",
    "train['Date'] = train['Date'].astype('int64')\n",
    "\n",
    "test['Date'] = pd.to_datetime(test['Date'])\n",
    "test['Date'] = test['Date'].astype('int64')\n",
    "\n",
    "#trainning data\n",
    "x_train = train.drop(\"Target\", axis=1)\n",
    "y_train = train[\"Target\"]\n",
    "\n",
    "#test data\n",
    "x_test = test.drop(\"Target\", axis=1)\n",
    "y_test = test[\"Target\"]\n",
    "\n",
    "#spliting data into train and validation\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=0.2, random_state=15)\n",
    "\n",
    "#scaling the data\n",
    "X_train_scaled, X_validation_scaled, X_test_scaled = scale(X_train, X_validation, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Random Forest</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the data\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=1)\n",
    "classifier.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5200945626477541\n",
      "Precision: 0.5225225225225225\n",
      "Recall: 0.5446009389671361\n",
      "F1-score: 0.5333333333333334\n",
      "AUC-ROC: 0.5199195171026156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.50      0.51       210\n",
      "           1       0.52      0.54      0.53       213\n",
      "\n",
      "    accuracy                           0.52       423\n",
      "   macro avg       0.52      0.52      0.52       423\n",
      "weighted avg       0.52      0.52      0.52       423\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 104                 106\n",
      "Actual Positive                  97                 116\n",
      "\n",
      "________________________________________________________________\n",
      "\n",
      "Accuracy: 0.5666666666666667\n",
      "Precision: 0.6923076923076923\n",
      "Recall: 0.5\n",
      "F1-score: 0.5806451612903226\n",
      "AUC-ROC: 0.5833333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.67      0.55        12\n",
      "           1       0.69      0.50      0.58        18\n",
      "\n",
      "    accuracy                           0.57        30\n",
      "   macro avg       0.58      0.58      0.57        30\n",
      "weighted avg       0.60      0.57      0.57        30\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                   8                   4\n",
      "Actual Positive                   9                   9\n"
     ]
    }
   ],
   "source": [
    "#model prediction on validation set\n",
    "predicted = classifier.predict(X_validation_scaled)\n",
    "info(y_validation, predicted, 'Random Forest', metrics_df_valid)\n",
    "\n",
    "print('\\n________________________________________________________________\\n')\n",
    "\n",
    "#model prediction on test set\n",
    "predicted = classifier.predict(X_test_scaled)\n",
    "info(y_test, predicted, 'Random Forest', metrics_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>SVM using linear kernel</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, kernel='linear')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the model\n",
    "#using c = 0.1 as hyperparameter\n",
    "svm = SVC(kernel='linear',C=0.1)\n",
    "svm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5271867612293144\n",
      "Precision: 0.5214521452145214\n",
      "Recall: 0.7417840375586855\n",
      "F1-score: 0.6124031007751939\n",
      "AUC-ROC: 0.5256539235412475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.31      0.39       210\n",
      "           1       0.52      0.74      0.61       213\n",
      "\n",
      "    accuracy                           0.53       423\n",
      "   macro avg       0.53      0.53      0.50       423\n",
      "weighted avg       0.53      0.53      0.50       423\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                  65                 145\n",
      "Actual Positive                  55                 158\n",
      "\n",
      "________________________________________________________________\n",
      "\n",
      "Accuracy: 0.6666666666666666\n",
      "Precision: 0.6818181818181818\n",
      "Recall: 0.8333333333333334\n",
      "F1-score: 0.7499999999999999\n",
      "AUC-ROC: 0.625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.42      0.50        12\n",
      "           1       0.68      0.83      0.75        18\n",
      "\n",
      "    accuracy                           0.67        30\n",
      "   macro avg       0.65      0.62      0.62        30\n",
      "weighted avg       0.66      0.67      0.65        30\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                   5                   7\n",
      "Actual Positive                   3                  15\n"
     ]
    }
   ],
   "source": [
    "#model prediction on validation set\n",
    "predicted = svm.predict(X_validation_scaled)\n",
    "info(y_validation, predicted, 'SVM-linear', metrics_df_valid)\n",
    "\n",
    "print('\\n________________________________________________________________\\n')\n",
    "\n",
    "#model prediction on test set\n",
    "predicted = svm.predict(X_test_scaled)\n",
    "info(y_test, predicted, 'SVM-linear', metrics_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>DecisionTree</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5035460992907801\n",
      "Precision: 0.5057915057915058\n",
      "Recall: 0.6150234741784038\n",
      "F1-score: 0.5550847457627119\n",
      "AUC-ROC: 0.5027498323272971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.39      0.44       210\n",
      "           1       0.51      0.62      0.56       213\n",
      "\n",
      "    accuracy                           0.50       423\n",
      "   macro avg       0.50      0.50      0.50       423\n",
      "weighted avg       0.50      0.50      0.50       423\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                  82                 128\n",
      "Actual Positive                  82                 131\n",
      "Accuracy: 0.6\n",
      "Precision: 0.6363636363636364\n",
      "Recall: 0.7777777777777778\n",
      "F1-score: 0.7000000000000001\n",
      "AUC-ROC: 0.5555555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.33      0.40        12\n",
      "           1       0.64      0.78      0.70        18\n",
      "\n",
      "    accuracy                           0.60        30\n",
      "   macro avg       0.57      0.56      0.55        30\n",
      "weighted avg       0.58      0.60      0.58        30\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                   4                   8\n",
      "Actual Positive                   4                  14\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "predicted = clf.predict(X_validation_scaled)\n",
    "info(y_validation, predicted, 'Decision Tree', metrics_df_valid)\n",
    "\n",
    "predicted = clf.predict(X_test_scaled)\n",
    "info(y_test, predicted, 'Decision Tree', metrics_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>now we use other models</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Quadratic Discriminant Analysis</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5437352245862884\n",
      "Precision: 0.5588235294117647\n",
      "Recall: 0.4460093896713615\n",
      "F1-score: 0.49608355091383816\n",
      "AUC-ROC: 0.5444332662642521\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.64      0.58       210\n",
      "           1       0.56      0.45      0.50       213\n",
      "\n",
      "    accuracy                           0.54       423\n",
      "   macro avg       0.55      0.54      0.54       423\n",
      "weighted avg       0.55      0.54      0.54       423\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                 135                  75\n",
      "Actual Positive                 118                  95\n",
      "Accuracy: 0.36666666666666664\n",
      "Precision: 0.4\n",
      "Recall: 0.1111111111111111\n",
      "F1-score: 0.1739130434782609\n",
      "AUC-ROC: 0.4305555555555556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.75      0.49        12\n",
      "           1       0.40      0.11      0.17        18\n",
      "\n",
      "    accuracy                           0.37        30\n",
      "   macro avg       0.38      0.43      0.33        30\n",
      "weighted avg       0.38      0.37      0.30        30\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                   9                   3\n",
      "Actual Positive                  16                   2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train_scaled, y_train)\n",
    "\n",
    "predicted = qda.predict(X_validation_scaled)\n",
    "info(y_validation, predicted, 'QDA', metrics_df_valid)\n",
    "\n",
    "predicted = qda.predict(X_test_scaled)\n",
    "info(y_test, predicted, 'QDA', metrics_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Logistic Regression model</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4728132387706856\n",
      "Precision: 0.48188405797101447\n",
      "Recall: 0.6244131455399061\n",
      "F1-score: 0.5439672801635992\n",
      "AUC-ROC: 0.4717303822937625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.32      0.38       210\n",
      "           1       0.48      0.62      0.54       213\n",
      "\n",
      "    accuracy                           0.47       423\n",
      "   macro avg       0.47      0.47      0.46       423\n",
      "weighted avg       0.47      0.47      0.46       423\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                  67                 143\n",
      "Actual Positive                  80                 133\n",
      "Accuracy: 0.6333333333333333\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.7777777777777778\n",
      "F1-score: 0.717948717948718\n",
      "AUC-ROC: 0.5972222222222221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.42      0.48        12\n",
      "           1       0.67      0.78      0.72        18\n",
      "\n",
      "    accuracy                           0.63        30\n",
      "   macro avg       0.61      0.60      0.60        30\n",
      "weighted avg       0.62      0.63      0.62        30\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                   5                   7\n",
      "Actual Positive                   4                  14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "predicted = logreg.predict(X_validation_scaled)\n",
    "info(y_validation, predicted, 'LogisticRegression', metrics_df_valid)\n",
    "\n",
    "predicted = logreg.predict(X_test_scaled)\n",
    "info(y_test, predicted, 'LogisticRegression', metrics_df_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Adaboost model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aminm\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.491725768321513\n",
      "Precision: 0.4963768115942029\n",
      "Recall: 0.6431924882629108\n",
      "F1-score: 0.5603271983640081\n",
      "AUC-ROC: 0.49064386317907444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.34      0.40       210\n",
      "           1       0.50      0.64      0.56       213\n",
      "\n",
      "    accuracy                           0.49       423\n",
      "   macro avg       0.49      0.49      0.48       423\n",
      "weighted avg       0.49      0.49      0.48       423\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                  71                 139\n",
      "Actual Positive                  76                 137\n",
      "\n",
      "________________________________________________________________\n",
      "\n",
      "Accuracy: 0.5666666666666667\n",
      "Precision: 0.631578947368421\n",
      "Recall: 0.6666666666666666\n",
      "F1-score: 0.6486486486486486\n",
      "AUC-ROC: 0.5416666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.42      0.43        12\n",
      "           1       0.63      0.67      0.65        18\n",
      "\n",
      "    accuracy                           0.57        30\n",
      "   macro avg       0.54      0.54      0.54        30\n",
      "weighted avg       0.56      0.57      0.56        30\n",
      "\n",
      "                 Predicted Negative  Predicted Positive\n",
      "Actual Negative                   5                   7\n",
      "Actual Positive                   6                  12\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_classifier = LogisticRegression()\n",
    "adaboost = AdaBoostClassifier(base_estimator=base_classifier)\n",
    "adaboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "predicted = adaboost.predict(X_validation_scaled)\n",
    "info(y_validation, predicted, 'AdaBoost', metrics_df_valid)\n",
    "\n",
    "print('\\n________________________________________________________________\\n')\n",
    "\n",
    "predicted = adaboost.predict(X_test_scaled)\n",
    "info(y_test, predicted, 'AdaBoost', metrics_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>models metrics for validation data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.520095</td>\n",
       "      <td>0.522523</td>\n",
       "      <td>0.544601</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.519920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-linear</td>\n",
       "      <td>0.527187</td>\n",
       "      <td>0.521452</td>\n",
       "      <td>0.741784</td>\n",
       "      <td>0.612403</td>\n",
       "      <td>0.525654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.503546</td>\n",
       "      <td>0.505792</td>\n",
       "      <td>0.615023</td>\n",
       "      <td>0.555085</td>\n",
       "      <td>0.502750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.543735</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.446009</td>\n",
       "      <td>0.496084</td>\n",
       "      <td>0.544433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.472813</td>\n",
       "      <td>0.481884</td>\n",
       "      <td>0.624413</td>\n",
       "      <td>0.543967</td>\n",
       "      <td>0.471730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.491726</td>\n",
       "      <td>0.496377</td>\n",
       "      <td>0.643192</td>\n",
       "      <td>0.560327</td>\n",
       "      <td>0.490644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  Precision    Recall  F1-score   AUC-ROC\n",
       "0       Random Forest  0.520095   0.522523  0.544601  0.533333  0.519920\n",
       "1          SVM-linear  0.527187   0.521452  0.741784  0.612403  0.525654\n",
       "2       Decision Tree  0.503546   0.505792  0.615023  0.555085  0.502750\n",
       "3                 QDA  0.543735   0.558824  0.446009  0.496084  0.544433\n",
       "4  LogisticRegression  0.472813   0.481884  0.624413  0.543967  0.471730\n",
       "5            AdaBoost  0.491726   0.496377  0.643192  0.560327  0.490644"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>models metrics for test data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM-linear</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.430556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.597222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  Precision    Recall  F1-score   AUC-ROC\n",
       "0       Random Forest  0.566667   0.692308  0.500000  0.580645  0.583333\n",
       "1          SVM-linear  0.666667   0.681818  0.833333  0.750000  0.625000\n",
       "2       Decision Tree  0.600000   0.636364  0.777778  0.700000  0.555556\n",
       "3                 QDA  0.366667   0.400000  0.111111  0.173913  0.430556\n",
       "4  LogisticRegression  0.633333   0.666667  0.777778  0.717949  0.597222\n",
       "5            AdaBoost  0.566667   0.631579  0.666667  0.648649  0.541667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
